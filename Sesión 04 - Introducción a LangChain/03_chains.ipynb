{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo III: Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo inicial en el uso de cadenas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada vez que se desee trabajar con una cadena, al menos, debe estar definido un prompt template e instanciado algún modelo de lenguaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=\"Cual es una buena actividad para realizar en {temporada}?\",\n",
    "            input_variables=[\"temporada\"],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "chat = ChatOpenAI(temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Cual es una buena actividad para realizar en primavera?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Una buena actividad para realizar en primavera es hacer un picnic en un parque o jardín. Puedes llevar comida y bebidas, una manta para sentarte y disfrutar del buen clima. También puedes aprovechar para caminar y apreciar la belleza de las flores y árboles en floración.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"primavera\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las cadenas tambien pueden ser instanciadas con un estado de \"memoria\"\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory #<--- golazo que veremos más adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=ConversationBufferMemory(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Dime los primeros 5 números de la serie de fibonacci\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Los primeros 5 números de la serie de Fibonacci son 0, 1, 1, 2, y 3.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"Dime los primeros 5 números de la serie de fibonacci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Dime los primeros 5 números de la serie de fibonacci\n",
      "AI: Los primeros 5 números de la serie de Fibonacci son 0, 1, 1, 2, y 3.\n",
      "Human: ¿Y cuál es el séptimo?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'El séptimo número de la serie de Fibonacci es 8.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"¿Y cuál es el séptimo?\") #<-- preserva el contexto de la pregunta anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Dime los primeros 5 números de la serie de fibonacci\n",
      "AI: Los primeros 5 números de la serie de Fibonacci son 0, 1, 1, 2, y 3.\n",
      "Human: ¿Y cuál es el séptimo?\n",
      "AI: El séptimo número de la serie de Fibonacci es 8.\n",
      "Human: ¿Y cual es el valor aproximado del cuociente entre el quinto y cuarto número de la secuencia?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'El cuarto número de la serie de Fibonacci es 2 y el quinto número es 3. Entonces, el cuociente entre el quinto y cuarto número sería 3/2, que es igual a 1.5.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"¿Y cual es el valor aproximado del cuociente entre el quinto y cuarto número de la secuencia?\") #<-- preserva el contexto de la pregunta anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cadenas Secuenciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este tipo de cadenas agregan valor cuando el output de una es utilizado como input de la siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta cadena está relacionada al postulante a chef\n",
    "llm = OpenAI(temperature=.7)\n",
    "chef_template = \"\"\"Actúa como un chef amateur. Yo te daré una temática y tu tarea será crear una receta en relación a esa temática.\n",
    "\n",
    "Temática: {tematica}\n",
    "Receta: Esta es la receta que has creado:\"\"\"\n",
    "chef_prompt_template = PromptTemplate(input_variables=[\"tematica\"], template=chef_template)\n",
    "chef_chain = LLMChain(llm=llm, prompt=chef_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta cadena está relacionada al experto evaluador de cocina\n",
    "llm = OpenAI(temperature=.7)\n",
    "template = \"\"\"Actúa como experto chef de cocina. Eres parte del comité experto que entrega la medalla Michelin de cocina. Tu tarea será entregar una evaluación a la propuesta del postulante bajo criterios de creatividad, originalidad y sabor. \n",
    "\n",
    "Receta:\n",
    "{receta}\n",
    "Evaluación crítica del chef experto del comité de la medalla Michelin:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"receta\"], template=template)\n",
    "review_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta es la cadena completa que toma en consideración las cadenas antes definidas\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chef_chain, review_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m \n",
      "\n",
      "Patagónico Carne Asada:\n",
      "\n",
      "Ingredientes:\n",
      "\n",
      "- 2kg de carne de ternera o de cordero\n",
      "- 2 cebollas\n",
      "- 2 dientes de ajo\n",
      "- 1 pimiento rojo\n",
      "- 2 cucharadas de aceite de oliva\n",
      "- Sal y pimienta al gusto\n",
      "- 2 cucharadas de orégano\n",
      "- 2 cucharadas de tomillo\n",
      "- 2 cucharadas de comino\n",
      "- 2 cucharadas de romero\n",
      "- 2 cucharadas de tomatera\n",
      "- 1 cucharada de vinagre de manzana\n",
      "\n",
      "Instrucciones:\n",
      "\n",
      "1. Precaliente el horno a 200 grados.\n",
      "\n",
      "2. En una sartén, a fuego medio, calienta el aceite de oliva y agrega la cebolla, el ajo y el pimiento. Saltea hasta que estén suaves.\n",
      "\n",
      "3. Mientras tanto, en un plato hondo, mezcla todas las\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "Esta receta ofrece una gran combinación de sabores y texturas. Los ingredientes se mezclan para crear un sabor único y original. El uso de los diferentes tipos de hierbas y especias, junto con el vinagre de manzana, aporta un toque ácido que equilibra el sabor a la perfección. La carne es cocinada al punto y se mantienen los jugos y la suavidad. En general, esta receta es un plato delicioso y creativo que seguramente será un éxito entre los comensales. La receta cumple con los criterios de creatividad, originalidad y sabor exigidos por el comité de la medalla Michelin.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "review = overall_chain.run(\"Un plato inspirado en la tierra patagónica\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asimismo, es posible incorporar más parámetros de entrada en las cadenas, y añadir memoria al proceso para que la información se conserve a lo largo de la secuencia.\n",
    "Referencia: https://python.langchain.com/docs/modules/chains/foundational/sequential_chains"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
