{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo Ib: Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de librerías\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Carga de keys\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de modelo\n",
    "llm = OpenAI(temperature=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt template con una variable\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"ice_cream\"],\n",
    "    template=\"Hola, deseo comprar un helado de {ice_cream}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "¡Hola! ¡Es fantástico que quieras comprar un helado de frutilla! ¿Qué tipo de helado quieres? ¿Una mini paleta, un cono, una tarrina o una bola?\n"
     ]
    }
   ],
   "source": [
    "#Le entregamos el valor del parámetro al prompt para luego ser entregado al modelo\n",
    "print(llm(prompt.format(ice_cream=\"frutilla\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se pueden entregar mútiples parámetros\n",
    "multiple_input_prompt = PromptTemplate(\n",
    "    input_variables=[\"ice_cream\", \"topping\"], \n",
    "    template=\"Hola, deseo comprar un helado de {ice_cream} con agregado de {topping}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hola, ¡encantado de servirte! Tenemos un delicioso helado de frutilla con baño de chocolate. Puedes ordenarlo ahora y te lo entregaremos en tu ubicación. ¡Disfruta tu postre!\n"
     ]
    }
   ],
   "source": [
    "print(llm(multiple_input_prompt.format(ice_cream=\"frutilla\", topping=\"baño de chocolate\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#También, podemos predefinir el template\n",
    "template = \"Hola, deseo comprar un helado de {ice_cream} con agregado de {topping}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ice_cream', 'topping']\n"
     ]
    }
   ],
   "source": [
    "#Observamos las variables involucradas\n",
    "print(prompt_template.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hola, te podemos ofrecer un delicioso helado de frutilla con baño de chocolate. ¡Esperamos que lo disfrutes!\n"
     ]
    }
   ],
   "source": [
    "#Respuesta del modelo\n",
    "print(llm(prompt_template.format(ice_cream=\"frutilla\", topping=\"baño de chocolate\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que sucede si se altera el ingreso de parámetros \n",
    "template = \"Hola, deseo comprar un helado de {ice_cream}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(template=template, \n",
    "                                 input_variables=[\"ice_cream\",\"topping\"], \n",
    "                                 validate_template=False) #cambiar a True para detectar el error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, deseo comprar un helado de frutilla\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.format(ice_cream=\"frutilla\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "¡Hola! ¡Qué buena idea! Encontrarás un helado de frutilla en la mayoría de los supermercados y heladerías. Si prefieres, también puedes hacer uno en casa. ¡Espero que disfrutes tu helado de frutilla!\n"
     ]
    }
   ],
   "source": [
    "#print(llm(prompt_template.format(ice_cream=\"frutilla\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que deseamos realizar ahora es que, mediante algunos ejemplos, el modelo reciba un contexto antes de generar su respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos una lista de ejemplos\n",
    "examples = [\n",
    "    {\"ice_cream\": \"piña\", \"topping\": \"trozos de fruta\"},\n",
    "    {\"ice_cream\": \"menta\", \"topping\": \"ralladura de jengibre\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le entregamos el formato para los ejemplos\n",
    "example_formatter_template = \"\"\"Hola, deseo comprar un helado de {ice_cream} con agregado de {topping}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos el template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"ice_cream\", \"topping\"],\n",
    "    template=example_formatter_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se instancia el objeto 'Few-shot Prompt Template'\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Genera pedidos de helados con un sabor y un agregado\\n\", # El prefix es una instrucción para que el LLM sepa que debe hacer con estos ejemplos\n",
    "    suffix=\"Hola, deseo comprar un helado de sandía con agregado de {input}\", # El suffix es donde se agrega el input del usuario para generar el texto que sigue\n",
    "    input_variables=[\"input\"], # indicamos la variable que se agregará al template\n",
    "    example_separator=\"\\n\", # string separador entre el prefix, examples y el suffix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genera pedidos de helados con un sabor y un agregado\n",
      "\n",
      "Hola, deseo comprar un helado de piña con agregado de trozos de fruta\n",
      "Hola, deseo comprar un helado de menta con agregado de ralladura de jengibre\n",
      "Hola, deseo comprar un helado de sandía con agregado de chocolate\n"
     ]
    }
   ],
   "source": [
    "# Generamos el prompt con la función format()\n",
    "print(few_shot_prompt.format(input=\"chocolate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " congelado\n"
     ]
    }
   ],
   "source": [
    "#print(llm(few_shot_prompt.format(input=\"melón\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunas situaciones será preferible almacenar prompt en vez de trabajarlo directamente en un código de python. Esta alternativa entrega flexibilidad para almacenamiento, para compartir y versionar prompts. Langchain es capaz de manipular archivos de formato JSON y YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import load_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = load_prompt(\"01_ex_serializacion.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â¿Que resulta de mezclar agua con aceite?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(element1=\"agua\", element2=\"aceite\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "La mezcla de agua con aceite no es posible debido a que el agua y el aceite no se mezclan entre sí. El agua es una sustancia polar y el aceite es una sustancia no polar, por lo que no se unen y se separan formando dos capas distintas.\n"
     ]
    }
   ],
   "source": [
    "#print(llm(prompt.format(element1=\"agua\", element2=\"aceite\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
